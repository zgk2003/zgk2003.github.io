<!DOCTYPE html>
<html>
<link rel="stylesheet" type="text/css" href="index.css">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Qian Huang</title>
    <style type="text/css">
    </style>
</head>

<body>
  <div class=row>
      <div class=left>
      <h1>Qian Huang</h1>
        <p> My research interest is in bridging "system 1" and "system 2" reasoning. One approach I find promising lies in allowing neural networks to reason over the underlying graph structure of data, especially in domains where this structure is not provided. I believe that doing so requires insights from both machine learning and graph algorithms. I am also interested in demystifying neural networks through exploring their robustness. </p>
        <p>I'm currently a first year PhD student at Stanford University.</p>
        <p> Links: [<a href="mailto:qh53@cornell.edu">Email</a>] [<a href="files/Qian_Huang.pdf">CV</a>] [<a href="https://scholar.google.com/citations?user=L3hkmG0AAAAJ&hl=en">Google Scholar</a>] </p>
    </div>
    <div class="container">
      <img  src="img/qian.jpg">
    </div>

  </div>

  <div height="200pt" width="100%" > <h2>Publications</h2>

  <ul>
  <li class="research_item">
    <div class="container grid-item" style="float:left">
        <img src="img/simple.png" >
    </div>
    <b>Combing Label Propagation and Simple Models Out-performs Graph Neural Networks</b>
    <br>
    <b>Qian Huang*</b>, Horace He* , Abhay Singh, Ser-Nam Lim, Austin Benson
    <br>
    <a href="https://openreview.net/forum?id=8E1-f3VhX1o"> Submitted to ICLR 2021 </a>
    <br>
    [<a href="https://openreview.net/forum?id=8E1-f3VhX1o">Paper</a>]
    <br>
    <b>TL;DR</b>: We demonstrated that for most popular transductive node classification tasks, state-of-the-art GNN models can be out-performed by a shallow MLP prediction followed by the post-processing of two Label Propagation variants. This simple framework directly uses label information and drastically reduces the parameters and runtimes needed to achieve state-of-the-art.
  </li>
  <hr>
  <li class="research_item">
    <div class="container grid-item" style="float:left">
        <img src="img/BSR.png" >
    </div>
    <b>Better Set Representations for Relational Reasoning</b>
    <br>
    <b>Qian Huang*</b>, Horace He* , Abhay Singh, Yan Zhang, Ser-Nam Lim, Austin Benson
    <br>
    <a href="https://arxiv.org/abs/2003.04448"> Accepted to NeurIPS 2020 </a>
    <br>
    [<a href="https://arxiv.org/abs/2003.04448">Paper</a>] [<a href="https://www.youtube.com/watch?v=Yhe5mZ-i6-Y">ICML OOL workshop Talk</a>]
    <br>
    <b>TL;DR</b>: Extracting sets of entities from unformatted data automatically is important for supporting reasoning models such as graph neural networks or transformers. Existing popular methods are generally task dependent or ignore the set structure. We show that by generating sets "properly", we can improve performance and robustness on a wide variety of tasks.
  </li>
  <hr>
  <li class="research_item">
    <div h class="container grid-item" style="float:left">
      <img src="img/ILA.png">
    </div>
    <b> Enhancing Adversarial Example Transferability with an Intermediate Level Attack </b>
    <br>
    <b>Qian Huang*</b>, Horace He*, Isay Katsman*, Zeqi Gu*, Serge Belongie, Ser-Nam Lim
    <br>
    <a href="http://iccv2019.thecvf.com/">ICCV 2019</a>
    <br>
    [<a href="https://arxiv.org/abs/1907.10823">Paper</a>] [<a href="https://slideslive.com/38922555/contributed-talk-5-enhancing-adversarial-example-transferability-with-an-intermediate-level-attack">Talk at WIML Workshop</a>] [<a href="https://twitter.com/cHHillee/status/1201705688898113536">Twitter Thread</a>] [<a href="https://news.cornell.edu/stories/2019/11/cs-undergrads-research-sets-sights-image-hackers">Cornell Chronicle</a>]
    <br>
    <b>TL;DR</b>: We can improve the transferability of an adversarial example significantly by maximizing the projection of perturbation onto its original perturbation direction in the feature space. Choosing the layer at which we optimize the projection changes the transferability significantly. Although we provided some justification for the method, it remains mysterious to us why this method can discover the vulnerability of other CNNs based on one model's vulnerability.
    <br>
  </li>
  <hr>

  </ul>
  </div>
</body>

</html>
